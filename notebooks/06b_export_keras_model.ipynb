{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f42118f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded trained weights successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\Negar\\Desktop\\paper_results\\Myself\\cr_coad_project\")\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "weights_path = \"results/images/baseline_image_weights_only.h5\"\n",
    "\n",
    "# Rebuild same architecture as training\n",
    "base = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    weights=\"imagenet\",\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "base.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base,\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Load learned weights from training\n",
    "model.load_weights(weights_path)\n",
    "print(\"✅ Loaded trained weights successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d002035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature extractor ready. Output shape: (None, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings from the EfficientNet base (before Dense layer)\n",
    "# --- Correct way to get EfficientNet feature extractor from a Sequential model ---\n",
    "# model.layers[0]  → EfficientNetB0 base\n",
    "base = model.layers[0]\n",
    "\n",
    "# Rebuild a clean functional model from EfficientNet's own input/output\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=base.input,\n",
    "    outputs=base.output\n",
    ")\n",
    "\n",
    "print(\"✅ Feature extractor ready. Output shape:\", feature_extractor.output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca36fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:03<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Embedding shape: (23, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "df = pd.read_csv(\"data/processed/images/rep_index.csv\")\n",
    "\n",
    "def decode_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "batch_size = 16\n",
    "paths = df[\"rep_slice\"].astype(str).tolist()\n",
    "ids = df[\"series_id\"].tolist()\n",
    "\n",
    "embeddings = []\n",
    "for i in tqdm(range(0, len(paths), batch_size)):\n",
    "    batch_paths = paths[i:i+batch_size]\n",
    "    imgs = tf.stack([decode_img(p) for p in batch_paths])\n",
    "    feats = feature_extractor.predict(imgs, verbose=0)\n",
    "    embeddings.append(feats)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "print(\"✅ Embedding shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc34f254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 1280-D embeddings to data/processed/images/image_embeddings_1280.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path(\"data/processed/images\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "embed_df = pd.DataFrame(embeddings)\n",
    "embed_df.insert(0, \"series_id\", ids)\n",
    "embed_df.to_csv(\"data/processed/images/image_embeddings_1280.csv\", index=False)\n",
    "\n",
    "print(\"✅ Saved 1280-D embeddings to data/processed/images/image_embeddings_1280.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce3b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/images/feature_extractor_keras_tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results/images/feature_extractor_keras_tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature extractor saved safely using tf.saved_model.save.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "save_dir = \"results/images/feature_extractor_keras_tf\"\n",
    "tf.saved_model.save(feature_extractor, save_dir)\n",
    "print(\"✅ Feature extractor saved safely using tf.saved_model.save.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
