{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d607962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "‚ö†Ô∏è No GPU detected ‚Äî training will use CPU (much slower).\n",
      "üñº Total image slices: 27822\n",
      "split\n",
      "train    19603\n",
      "test      4166\n",
      "val       4053\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Labels assigned: 1195 metastatic, 26627 non-metastatic\n",
      "üìä Label distribution:\n",
      " label\n",
      "0    26627\n",
      "1     1195\n",
      "Name: count, dtype: int64\n",
      "üìä Using subset for quick test:\n",
      "  Train: 1960  Val: 405  Test: 416\n",
      "‚úÖ Datasets ready ‚Äî Train: 19603, Val: 4053, Test: 4166\n",
      "\n",
      "üöÄ Training model: EfficientNetB3\n",
      "Epoch 1/3\n",
      "  1/123 [..............................] - ETA: 2:35:30 - loss: 0.6898 - accuracy: 0.5625 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 06_train_image_model.ipynb ‚Äî Multi-Architecture Full Training\n",
    "# =============================================================\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\Negar\\Desktop\\paper_results\\Myself\\cr_coad_project\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Environment setup\n",
    "# -------------------------------------------------------------\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU detected: {gpus}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected ‚Äî training will use CPU (much slower).\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Parameters\n",
    "# -------------------------------------------------------------\n",
    "IMG_SIZE = (300, 300)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "SEED = 42\n",
    "\n",
    "DATA_DIR = Path(\"data/processed/images/all_slices\")\n",
    "INDEX = Path(\"data/processed/images/all_index.csv\")\n",
    "SPLIT_DIR = Path(\"data/splits\")\n",
    "CLINICAL_PATH = Path(\"data/processed/clinical/clinical_features_with_id.csv\")\n",
    "SAVE_DIR = Path(\"results/images/multi_architecture\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Load datasets + splits\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(INDEX)\n",
    "train_ids = pd.read_csv(SPLIT_DIR / \"train_series.csv\")[\"series_id\"].tolist()\n",
    "val_ids   = pd.read_csv(SPLIT_DIR / \"val_series.csv\")[\"series_id\"].tolist()\n",
    "test_ids  = pd.read_csv(SPLIT_DIR / \"test_series.csv\")[\"series_id\"].tolist()\n",
    "\n",
    "def assign_split(sid):\n",
    "    if sid in train_ids: return \"train\"\n",
    "    if sid in val_ids:   return \"val\"\n",
    "    if sid in test_ids:  return \"test\"\n",
    "    return \"ignore\"\n",
    "\n",
    "df[\"split\"] = df[\"series_id\"].map(assign_split)\n",
    "df = df[df[\"split\"] != \"ignore\"]\n",
    "\n",
    "print(\"üñº Total image slices:\", len(df))\n",
    "print(df[\"split\"].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Merge with clinical metastasis labels\n",
    "# -------------------------------------------------------------\n",
    "clinical = pd.read_csv(CLINICAL_PATH)\n",
    "clinical.columns = clinical.columns.str.strip()\n",
    "meta_col = next((c for c in clinical.columns if \"metastasis\" in c.lower()), None)\n",
    "if meta_col is None:\n",
    "    raise SystemExit(\"‚ùå No metastasis column found in clinical data!\")\n",
    "\n",
    "merged = df.merge(clinical[[\"patient_id\", meta_col]], on=\"patient_id\", how=\"left\")\n",
    "possible_cols = [c for c in merged.columns if \"metastasis\" in c.lower()]\n",
    "meta_col_final = possible_cols[0]\n",
    "merged = merged.rename(columns={meta_col_final: \"metastasis_status\"})\n",
    "\n",
    "merged[\"label\"] = merged[\"metastasis_status\"].replace({\n",
    "    1: 1, 0: 0,\n",
    "    \"yes\": 1, \"metastatic\": 1, \"positive\": 1,\n",
    "    \"no\": 0, \"non-metastatic\": 0, \"negative\": 0\n",
    "})\n",
    "merged[\"label\"] = pd.to_numeric(merged[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "print(f\"‚úÖ Labels assigned: {merged['label'].sum()} metastatic, {len(merged)-merged['label'].sum()} non-metastatic\")\n",
    "print(\"üìä Label distribution:\\n\", merged['label'].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# TensorFlow dataset builders\n",
    "# -------------------------------------------------------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "def make_dataset(subdf, augment=False, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((subdf[\"slice_path\"].values, subdf[\"label\"].values))\n",
    "    ds = ds.map(lambda p, y: (decode_img(p), y), num_parallel_calls=AUTOTUNE)\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        ds = ds.map(lambda x, y: (tf.image.random_brightness(x, 0.15), y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(2048, seed=SEED)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Subsample the dataset for a quick test run\n",
    "# -------------------------------------------------------------\n",
    "# Full-size:\n",
    "# train: 19603, val: 4053, test: 4166\n",
    "# Sample target: ~10% of each\n",
    "train_df = merged[merged.split == \"train\"].sample(n=1960, random_state=42)\n",
    "val_df   = merged[merged.split == \"val\"].sample(n=405, random_state=42)\n",
    "test_df  = merged[merged.split == \"test\"].sample(n=416, random_state=42)\n",
    "\n",
    "print(f\"üìä Using subset for quick test:\")\n",
    "print(f\"  Train: {len(train_df)}  Val: {len(val_df)}  Test: {len(test_df)}\")\n",
    "\n",
    "train_ds = make_dataset(train_df, augment=True)\n",
    "val_ds   = make_dataset(val_df)\n",
    "test_ds  = make_dataset(test_df, shuffle=False)\n",
    "\n",
    "# train_ds = make_dataset(merged[merged.split==\"train\"], augment=True)\n",
    "# val_ds   = make_dataset(merged[merged.split==\"val\"])\n",
    "# test_ds  = make_dataset(merged[merged.split==\"test\"], shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Datasets ready ‚Äî Train: {len(merged[merged.split=='train'])}, Val: {len(merged[merged.split=='val'])}, Test: {len(merged[merged.split=='test'])}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Safe logging helpers\n",
    "# -------------------------------------------------------------\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        if hasattr(x, \"numpy\"):\n",
    "            x = x.numpy()\n",
    "        if isinstance(x, (np.ndarray, list, tuple)):\n",
    "            return float(np.mean(x))\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "class SafeJSONCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs:\n",
    "            for k, v in logs.items():\n",
    "                logs[k] = safe_float(v)\n",
    "\n",
    "class SafeReduceLROnPlateau(tf.keras.callbacks.ReduceLROnPlateau):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = {k: safe_float(v) for k, v in (logs or {}).items()}\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "# =============================================================\n",
    "# üîÑ Multi-Architecture Training\n",
    "# =============================================================\n",
    "architectures = {\n",
    "    \"EfficientNetB3\": tf.keras.applications.EfficientNetB3,\n",
    "    \"EfficientNetV2S\": tf.keras.applications.EfficientNetV2S,\n",
    "    \"DenseNet121\": tf.keras.applications.DenseNet121,\n",
    "    \"ConvNeXtTiny\": tf.keras.applications.ConvNeXtTiny\n",
    "}\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for name, Backbone in architectures.items():\n",
    "    print(f\"\\nüöÄ Training model: {name}\")\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    base = Backbone(include_top=False, input_shape=IMG_SIZE + (3,), weights=\"imagenet\", pooling=\"avg\")\n",
    "    base.trainable = True\n",
    "\n",
    "    inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "    x = base(inputs, training=True)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\"),\n",
    "                 tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")]\n",
    "    )\n",
    "\n",
    "    checkpoint_path = SAVE_DIR / f\"{name}_best.weights.h5\"\n",
    "\n",
    "    callbacks = [\n",
    "        SafeJSONCallback(),\n",
    "        EarlyStopping(monitor=\"val_auc\", patience=5, mode=\"max\", restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=str(checkpoint_path),\n",
    "                        monitor=\"val_auc\", save_best_only=True,\n",
    "                        save_weights_only=True, mode=\"max\", verbose=1),\n",
    "        SafeReduceLROnPlateau(monitor=\"val_auc\", factor=0.3, patience=3, verbose=1, mode=\"max\")\n",
    "    ]\n",
    "\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks, verbose=1)\n",
    "    results = model.evaluate(test_ds, return_dict=True)\n",
    "\n",
    "    print(f\"‚úÖ Final Test Results ({name}):\")\n",
    "    for k, v in results.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "    # Save training history and model\n",
    "    pd.DataFrame(history.history).to_csv(SAVE_DIR / f\"{name}_training_history.csv\", index=False)\n",
    "    tf.saved_model.save(model, str(SAVE_DIR / f\"{name}_full_model\"))\n",
    "    results_summary.append({\"model\": name, **results})\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Save summary table\n",
    "# -------------------------------------------------------------\n",
    "summary_df = pd.DataFrame(results_summary)\n",
    "summary_path = SAVE_DIR / \"architecture_comparison_summary.csv\"\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "print(\"\\nüìä Saved architecture comparison summary:\")\n",
    "print(summary_df)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Visualization\n",
    "# -------------------------------------------------------------\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(summary_df[\"model\"], summary_df[\"accuracy\"], label=\"Accuracy\", alpha=0.7)\n",
    "plt.bar(summary_df[\"model\"], summary_df[\"auc\"], label=\"AUC\", alpha=0.7)\n",
    "plt.title(\"Model Comparison: Accuracy & AUC\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / \"architecture_comparison_barplot.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================\n",
    "# üß† Extract embeddings from best-performing model (by AUC)\n",
    "# =============================================================\n",
    "best_model_name = summary_df.loc[summary_df[\"auc\"].idxmax(), \"model\"]\n",
    "print(f\"\\nüèÜ Best-performing model: {best_model_name}\")\n",
    "\n",
    "best_model_path = SAVE_DIR / f\"{best_model_name}_full_model\"\n",
    "best_model = tf.keras.models.load_model(best_model_path)\n",
    "\n",
    "feature_extractor = tf.keras.Model(inputs=best_model.input, outputs=best_model.layers[-2].output)\n",
    "\n",
    "print(f\"üîç Extracting feature embeddings using {best_model_name}...\")\n",
    "all_paths = merged[\"slice_path\"].tolist()\n",
    "batch_size = 32\n",
    "embeddings = []\n",
    "\n",
    "for i in range(0, len(all_paths), batch_size):\n",
    "    batch_imgs = [decode_img(p) for p in all_paths[i:i+batch_size]]\n",
    "    batch_tensor = tf.stack(batch_imgs)\n",
    "    emb = feature_extractor(batch_tensor).numpy()\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "np.save(SAVE_DIR / f\"{best_model_name}_embeddings.npy\", embeddings)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"slice_path\": all_paths,\n",
    "    \"label\": merged[\"label\"].tolist()\n",
    "}).to_csv(SAVE_DIR / f\"{best_model_name}_embeddings_index.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Embeddings saved: {embeddings.shape} ‚Üí {SAVE_DIR / f'{best_model_name}_embeddings.npy'}\")\n",
    "print(\"üéØ All training, evaluation, and embedding extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5db0c061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "‚ö†Ô∏è No GPU detected ‚Äî training will use CPU (much slower).\n",
      "üñº Total image slices: 27822\n",
      "split\n",
      "train    19603\n",
      "test      4166\n",
      "val       4053\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Labels assigned: 1195 metastatic, 26627 non-metastatic\n",
      "üìä Label distribution:\n",
      " label\n",
      "0    26627\n",
      "1     1195\n",
      "Name: count, dtype: int64\n",
      "üìä Using subset for quick test:\n",
      "  Train: 1960  Val: 405  Test: 416\n",
      "‚úÖ Datasets ready ‚Äî Train: 19603, Val: 4053, Test: 4166\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 300, 300, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1537      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,785,072\n",
      "Trainable params: 10,697,769\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n",
      "üöÄ Starting new training run from scratch...\n",
      "Epoch 1/3\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9490 - auc: 0.9035 - precision: 0.4783 - recall: 0.3402 \n",
      "Epoch 1: val_auc improved from -inf to 0.99984, saving model to results\\images\\best_image_model.weights.h5\n",
      "123/123 [==============================] - 1832s 15s/step - loss: 0.1470 - accuracy: 0.9490 - auc: 0.9035 - precision: 0.4783 - recall: 0.3402 - val_loss: 0.0368 - val_accuracy: 0.9951 - val_auc: 0.9998 - val_precision: 0.9375 - val_recall: 0.9375\n",
      "Epoch 2/3\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9888 - auc: 0.9929 - precision: 0.9518 - recall: 0.8144 \n",
      "Epoch 2: val_auc did not improve from 0.99984\n",
      "123/123 [==============================] - 1774s 14s/step - loss: 0.0338 - accuracy: 0.9888 - auc: 0.9929 - precision: 0.9518 - recall: 0.8144 - val_loss: 0.0559 - val_accuracy: 0.9704 - val_auc: 0.9912 - val_precision: 0.6250 - val_recall: 0.6250\n",
      "Epoch 3/3\n",
      "123/123 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9949 - auc: 0.9990 - precision: 0.9780 - recall: 0.9175 \n",
      "Epoch 3: val_auc improved from 0.99984 to 1.00000, saving model to results\\images\\best_image_model.weights.h5\n",
      "123/123 [==============================] - 1772s 14s/step - loss: 0.0191 - accuracy: 0.9949 - auc: 0.9990 - precision: 0.9780 - recall: 0.9175 - val_loss: 0.0106 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000\n",
      "26/26 [==============================] - 131s 5s/step - loss: 0.0166 - accuracy: 0.9904 - auc: 0.9992 - precision: 0.8333 - recall: 0.9375\n",
      "\n",
      "‚úÖ Final Test Results:\n",
      "loss: 0.0166\n",
      "accuracy: 0.9904\n",
      "auc: 0.9992\n",
      "precision: 0.8333\n",
      "recall: 0.9375\n",
      "\n",
      "üíæ Saving model and feature embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 131). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results\\images\\baseline_image_model_full_tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: results\\images\\baseline_image_model_full_tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved successfully (TensorFlow SavedModel format).\n",
      "‚úÖ Embeddings saved: (27822, 1536) ‚Üí results\\images\\image_embeddings_full.npy\n",
      "üéØ Training complete.\n",
      "\n",
      "üìä Generating comparison plots...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results\\\\images\\\\architecture_comparison_summary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 277\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müìä Generating comparison plots...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# --- Load summary file\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAVE_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchitecture_comparison_summary.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# --- Accuracy & AUC bar plot\u001b[39;00m\n\u001b[0;32m    280\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Negar\\anaconda3\\envs\\crlm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Negar\\anaconda3\\envs\\crlm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Negar\\anaconda3\\envs\\crlm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Negar\\anaconda3\\envs\\crlm\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Negar\\anaconda3\\envs\\crlm\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results\\\\images\\\\architecture_comparison_summary.csv'"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 06_train_image_model.ipynb ‚Äî Full Model (Flexible Architecture)\n",
    "# =============================================================\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\Negar\\Desktop\\paper_results\\Myself\\cr_coad_project\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Environment setup\n",
    "# -------------------------------------------------------------\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU detected: {gpus}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected ‚Äî training will use CPU (much slower).\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Parameters\n",
    "# -------------------------------------------------------------\n",
    "IMG_SIZE = (300, 300)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "SEED = 42\n",
    "\n",
    "DATA_DIR = Path(\"data/processed/images/all_slices\")\n",
    "INDEX = Path(\"data/processed/images/all_index.csv\")\n",
    "SPLIT_DIR = Path(\"data/splits\")\n",
    "CLINICAL_PATH = Path(\"data/processed/clinical/clinical_features_with_id.csv\")\n",
    "SAVE_DIR = Path(\"results/images\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Load datasets + splits\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(INDEX)\n",
    "train_ids = pd.read_csv(SPLIT_DIR / \"train_series.csv\")[\"series_id\"].tolist()\n",
    "val_ids   = pd.read_csv(SPLIT_DIR / \"val_series.csv\")[\"series_id\"].tolist()\n",
    "test_ids  = pd.read_csv(SPLIT_DIR / \"test_series.csv\")[\"series_id\"].tolist()\n",
    "\n",
    "def assign_split(sid):\n",
    "    if sid in train_ids: return \"train\"\n",
    "    if sid in val_ids:   return \"val\"\n",
    "    if sid in test_ids:  return \"test\"\n",
    "    return \"ignore\"\n",
    "\n",
    "df[\"split\"] = df[\"series_id\"].map(assign_split)\n",
    "df = df[df[\"split\"] != \"ignore\"]\n",
    "\n",
    "print(\"üñº Total image slices:\", len(df))\n",
    "print(df[\"split\"].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Merge with clinical metastasis labels\n",
    "# -------------------------------------------------------------\n",
    "clinical = pd.read_csv(CLINICAL_PATH)\n",
    "clinical.columns = clinical.columns.str.strip()\n",
    "meta_col = next((c for c in clinical.columns if \"metastasis\" in c.lower()), None)\n",
    "if meta_col is None:\n",
    "    raise SystemExit(\"‚ùå No metastasis column found in clinical data!\")\n",
    "\n",
    "merged = df.merge(clinical[[\"patient_id\", meta_col]], on=\"patient_id\", how=\"left\")\n",
    "\n",
    "possible_cols = [c for c in merged.columns if \"metastasis\" in c.lower()]\n",
    "meta_col_final = possible_cols[0]\n",
    "merged = merged.rename(columns={meta_col_final: \"metastasis_status\"})\n",
    "\n",
    "merged[\"label\"] = merged[\"metastasis_status\"].replace({\n",
    "    1: 1, 0: 0,\n",
    "    \"yes\": 1, \"metastatic\": 1, \"positive\": 1,\n",
    "    \"no\": 0, \"non-metastatic\": 0, \"negative\": 0\n",
    "})\n",
    "merged[\"label\"] = pd.to_numeric(merged[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "print(f\"‚úÖ Labels assigned: {merged['label'].sum()} metastatic, {len(merged)-merged['label'].sum()} non-metastatic\")\n",
    "print(\"üìä Label distribution:\\n\", merged['label'].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# TensorFlow dataset builders\n",
    "# -------------------------------------------------------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "def make_dataset(subdf, augment=False, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((subdf[\"slice_path\"].values, subdf[\"label\"].values))\n",
    "    ds = ds.map(lambda p, y: (decode_img(p), y), num_parallel_calls=AUTOTUNE)\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        ds = ds.map(lambda x, y: (tf.image.random_brightness(x, 0.15), y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(2048, seed=SEED)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Subsample the dataset for a quick test run\n",
    "# -------------------------------------------------------------\n",
    "# Full-size:\n",
    "# train: 19603, val: 4053, test: 4166\n",
    "# Sample target: ~10% of each\n",
    "train_df = merged[merged.split == \"train\"].sample(n=1960, random_state=42)\n",
    "val_df   = merged[merged.split == \"val\"].sample(n=405, random_state=42)\n",
    "test_df  = merged[merged.split == \"test\"].sample(n=416, random_state=42)\n",
    "\n",
    "print(f\"üìä Using subset for quick test:\")\n",
    "print(f\"  Train: {len(train_df)}  Val: {len(val_df)}  Test: {len(test_df)}\")\n",
    "\n",
    "train_ds = make_dataset(train_df, augment=True)\n",
    "val_ds   = make_dataset(val_df)\n",
    "test_ds  = make_dataset(test_df, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Datasets ready ‚Äî Train: {len(merged[merged.split=='train'])}, Val: {len(merged[merged.split=='val'])}, Test: {len(merged[merged.split=='test'])}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Clear session before building a big model\n",
    "# -------------------------------------------------------------\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# üÜï Model definition (you can switch backbone here)\n",
    "# -------------------------------------------------------------\n",
    "# Available options: EfficientNetB3, EfficientNetV2S, DenseNet121, ConvNeXtTiny\n",
    "Backbone = tf.keras.applications.EfficientNetB3   # <-- Change this line to test others\n",
    "\n",
    "base = Backbone(\n",
    "    include_top=False,\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    weights=\"imagenet\",\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "base.trainable = True\n",
    "\n",
    "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "x = base(inputs, training=True)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\"),\n",
    "             tf.keras.metrics.Precision(name=\"precision\"),\n",
    "             tf.keras.metrics.Recall(name=\"recall\")]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Callbacks (JSON-safe + resume-ready)\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "\n",
    "def safe_float(x):\n",
    "    try:\n",
    "        if hasattr(x, \"numpy\"):\n",
    "            x = x.numpy()\n",
    "        if isinstance(x, (np.ndarray, list, tuple)):\n",
    "            return float(np.mean(x))\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "class SafeJSONCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs:\n",
    "            for k, v in logs.items():\n",
    "                logs[k] = safe_float(v)\n",
    "\n",
    "class SafeReduceLROnPlateau(tf.keras.callbacks.ReduceLROnPlateau):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = {k: safe_float(v) for k, v in (logs or {}).items()}\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "checkpoint_path = SAVE_DIR / \"best_image_model.weights.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    SafeJSONCallback(),\n",
    "    EarlyStopping(monitor=\"val_auc\", patience=5, mode=\"max\", restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath=str(checkpoint_path),\n",
    "                    monitor=\"val_auc\", save_best_only=True,\n",
    "                    save_weights_only=True, mode=\"max\", verbose=1),\n",
    "    SafeReduceLROnPlateau(monitor=\"val_auc\", factor=0.3, patience=3, verbose=1, mode=\"max\")\n",
    "]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Resume from checkpoint if available\n",
    "# -------------------------------------------------------------\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"üîÅ Found existing checkpoint at {checkpoint_path}, loading weights...\")\n",
    "    model.load_weights(checkpoint_path)\n",
    "else:\n",
    "    print(\"üöÄ Starting new training run from scratch...\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Determine last completed epoch\n",
    "# -------------------------------------------------------------\n",
    "history_path = SAVE_DIR / \"training_history_best.csv\"\n",
    "initial_epoch = 0\n",
    "if history_path.exists():\n",
    "    hist = pd.read_csv(history_path)\n",
    "    initial_epoch = len(hist)\n",
    "    print(f\"‚è© Resuming training from epoch {initial_epoch} of {EPOCHS}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Train\n",
    "# -------------------------------------------------------------\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Evaluate\n",
    "# -------------------------------------------------------------\n",
    "results = model.evaluate(test_ds, return_dict=True)\n",
    "print(\"\\n‚úÖ Final Test Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "pd.DataFrame(history.history).to_csv(SAVE_DIR / \"training_history_best.csv\", index=False)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Save model and feature embeddings\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüíæ Saving model and feature embeddings...\")\n",
    "\n",
    "tf.saved_model.save(model, str(SAVE_DIR / \"baseline_image_model_full_tf\"))\n",
    "print(\"‚úÖ Model saved successfully (TensorFlow SavedModel format).\")\n",
    "\n",
    "# Extract feature embeddings\n",
    "feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "all_paths = merged[\"slice_path\"].tolist()\n",
    "batch_size = 32\n",
    "embeddings = []\n",
    "\n",
    "for i in range(0, len(all_paths), batch_size):\n",
    "    batch_imgs = [decode_img(p) for p in all_paths[i:i+batch_size]]\n",
    "    batch_tensor = tf.stack(batch_imgs)\n",
    "    emb = feature_extractor(batch_tensor).numpy()\n",
    "    embeddings.append(emb)\n",
    "\n",
    "embeddings = np.vstack(embeddings)\n",
    "np.save(SAVE_DIR / \"image_embeddings_full.npy\", embeddings)\n",
    "pd.DataFrame({\n",
    "    \"slice_path\": all_paths,\n",
    "    \"label\": merged[\"label\"].tolist()\n",
    "}).to_csv(SAVE_DIR / \"image_embeddings_index_full.csv\", index=False)\n",
    "\n",
    "print(f\"‚úÖ Embeddings saved: {embeddings.shape} ‚Üí {SAVE_DIR/'image_embeddings_full.npy'}\")\n",
    "print(\"üéØ Training complete.\")\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# üÜï NEW SECTION ‚Äî Visualization of Results\n",
    "# =============================================================\n",
    "\n",
    "print(\"\\nüìä Generating comparison plots...\")\n",
    "\n",
    "# --- Load summary file\n",
    "summary = pd.read_csv(SAVE_DIR / \"architecture_comparison_summary.csv\")\n",
    "\n",
    "# --- Accuracy & AUC bar plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(summary[\"model\"], summary[\"accuracy\"], label=\"Accuracy\", alpha=0.7)\n",
    "plt.bar(summary[\"model\"], summary[\"auc\"], label=\"AUC\", alpha=0.7)\n",
    "plt.title(\"Model Comparison: Accuracy & AUC\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.legend()\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(SAVE_DIR / \"architecture_comparison_barplot.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Training curves per model\n",
    "for name in summary[\"model\"]:\n",
    "    hist_path = SAVE_DIR / f\"{name}_training_history.csv\"\n",
    "    if hist_path.exists():\n",
    "        hist = pd.read_csv(hist_path)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(hist[\"accuracy\"], label=\"Train Accuracy\")\n",
    "        plt.plot(hist[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "        plt.plot(hist[\"auc\"], label=\"Train AUC\")\n",
    "        plt.plot(hist[\"val_auc\"], label=\"Val AUC\")\n",
    "        plt.title(f\"Training Curves ‚Äî {name}\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Metric\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(SAVE_DIR / f\"{name}_training_curves.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ All plots saved to:\", SAVE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a284f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea87f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Negar\\anaconda3\\envs\\crlm\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "‚ö†Ô∏è No GPU detected ‚Äî training will use CPU (much slower).\n",
      "üñº Total image slices: 27822\n",
      "split\n",
      "train    19603\n",
      "test      4166\n",
      "val       4053\n",
      "Name: count, dtype: int64\n",
      "‚úÖ Labels assigned: 1195 metastatic, 26627 non-metastatic\n",
      "üìä Label distribution:\n",
      " label\n",
      "0    26627\n",
      "1     1195\n",
      "Name: count, dtype: int64\n",
      "üìä Using subset for quick test:\n",
      "  Train: 3920  Val: 810  Test: 833\n",
      "‚úÖ Datasets ready ‚Äî Train: 19603, Val: 4053, Test: 4166\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 300, 300, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb3 (Functional)  (None, 1536)             10783535  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1536)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1537      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,785,072\n",
      "Trainable params: 10,697,769\n",
      "Non-trainable params: 87,303\n",
      "_________________________________________________________________\n",
      "üöÄ Starting new training run from scratch...\n",
      "Epoch 1/3\n",
      "  4/245 [..............................] - ETA: 1:03:46 - loss: 0.6848 - accuracy: 0.5000 - auc: 0.5356 - precision: 0.0345 - recall: 0.2000"
     ]
    }
   ],
   "source": [
    "# =============================================================\n",
    "# 06_train_image_model.ipynb ‚Äî Full EfficientNetB3 model\n",
    "# =============================================================\n",
    "import os\n",
    "os.chdir(r\"C:\\Users\\Negar\\Desktop\\paper_results\\Myself\\cr_coad_project\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Environment setup\n",
    "# -------------------------------------------------------------\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"‚úÖ GPU detected: {gpus}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected ‚Äî training will use CPU (much slower).\")\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (300, 300)        # EfficientNetB3 default input\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "SEED = 42\n",
    "\n",
    "DATA_DIR = Path(\"data/processed/images/all_slices\")\n",
    "INDEX = Path(\"data/processed/images/all_index.csv\")\n",
    "SPLIT_DIR = Path(\"data/splits\")\n",
    "CLINICAL_PATH = Path(\"data/processed/clinical/clinical_features_with_id.csv\")\n",
    "SAVE_DIR = Path(\"results/images\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Load datasets + splits\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(INDEX)\n",
    "train_ids = pd.read_csv(SPLIT_DIR / \"train_series.csv\")[\"series_id\"].tolist()\n",
    "val_ids   = pd.read_csv(SPLIT_DIR / \"val_series.csv\")[\"series_id\"].tolist()\n",
    "test_ids  = pd.read_csv(SPLIT_DIR / \"test_series.csv\")[\"series_id\"].tolist()\n",
    "\n",
    "def assign_split(sid):\n",
    "    if sid in train_ids: return \"train\"\n",
    "    if sid in val_ids:   return \"val\"\n",
    "    if sid in test_ids:  return \"test\"\n",
    "    return \"ignore\"\n",
    "\n",
    "df[\"split\"] = df[\"series_id\"].map(assign_split)\n",
    "df = df[df[\"split\"] != \"ignore\"]\n",
    "\n",
    "print(\"üñº Total image slices:\", len(df))\n",
    "print(df[\"split\"].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Merge with clinical metastasis labels\n",
    "# -------------------------------------------------------------\n",
    "clinical = pd.read_csv(CLINICAL_PATH)\n",
    "clinical.columns = clinical.columns.str.strip()\n",
    "meta_col = next((c for c in clinical.columns if \"metastasis\" in c.lower()), None)\n",
    "if meta_col is None:\n",
    "    raise SystemExit(\"‚ùå No metastasis column found in clinical data!\")\n",
    "\n",
    "merged = df.merge(clinical[[\"patient_id\", meta_col]], on=\"patient_id\", how=\"left\")\n",
    "\n",
    "possible_cols = [c for c in merged.columns if \"metastasis\" in c.lower()]\n",
    "meta_col_final = possible_cols[0]\n",
    "merged = merged.rename(columns={meta_col_final: \"metastasis_status\"})\n",
    "\n",
    "merged[\"label\"] = merged[\"metastasis_status\"].replace({\n",
    "    1: 1, 0: 0,\n",
    "    \"yes\": 1, \"metastatic\": 1, \"positive\": 1,\n",
    "    \"no\": 0, \"non-metastatic\": 0, \"negative\": 0\n",
    "})\n",
    "merged[\"label\"] = pd.to_numeric(merged[\"label\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "print(f\"‚úÖ Labels assigned: {merged['label'].sum()} metastatic, {len(merged)-merged['label'].sum()} non-metastatic\")\n",
    "print(\"üìä Label distribution:\\n\", merged['label'].value_counts())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# TensorFlow dataset builders\n",
    "# -------------------------------------------------------------\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def decode_img(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "def make_dataset(subdf, augment=False, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((subdf[\"slice_path\"].values, subdf[\"label\"].values))\n",
    "    ds = ds.map(lambda p, y: (decode_img(p), y), num_parallel_calls=AUTOTUNE)\n",
    "    if augment:\n",
    "        ds = ds.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        ds = ds.map(lambda x, y: (tf.image.random_brightness(x, 0.15), y))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(2048, seed=SEED)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Subsample the dataset for a quick test run\n",
    "# -------------------------------------------------------------\n",
    "# Full-size:\n",
    "# train: 19603, val: 4053, test: 4166\n",
    "# Sample target: ~10% of each\n",
    "train_df = merged[merged.split == \"train\"].sample(n=3920, random_state=42)\n",
    "val_df   = merged[merged.split == \"val\"].sample(n=810, random_state=42)\n",
    "test_df  = merged[merged.split == \"test\"].sample(n=833, random_state=42)\n",
    "\n",
    "print(f\"üìä Using subset for quick test:\")\n",
    "print(f\"  Train: {len(train_df)}  Val: {len(val_df)}  Test: {len(test_df)}\")\n",
    "\n",
    "train_ds = make_dataset(train_df, augment=True)\n",
    "val_ds   = make_dataset(val_df)\n",
    "test_ds  = make_dataset(test_df, shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Datasets ready ‚Äî Train: {len(merged[merged.split=='train'])}, Val: {len(merged[merged.split=='val'])}, Test: {len(merged[merged.split=='test'])}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Model definition ‚Äî EfficientNetB3\n",
    "# -------------------------------------------------------------\n",
    "base = tf.keras.applications.EfficientNetB3(\n",
    "    include_top=False,\n",
    "    input_shape=IMG_SIZE + (3,),\n",
    "    weights=\"imagenet\",\n",
    "    pooling=\"avg\"\n",
    ")\n",
    "base.trainable = True   # fine-tune all layers (can freeze first N later)\n",
    "\n",
    "inputs = layers.Input(shape=IMG_SIZE + (3,))\n",
    "x = base(inputs, training=True)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Callbacks (With JSON-safe and weight-only checkpoints)\n",
    "# -------------------------------------------------------------\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def safe_float(x):\n",
    "    \"\"\"Convert any metric value (tensor/ndarray) to plain float.\"\"\"\n",
    "    try:\n",
    "        if hasattr(x, \"numpy\"):\n",
    "            x = x.numpy()\n",
    "        if isinstance(x, (np.ndarray, list, tuple)):\n",
    "            return float(np.mean(x))\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "class SafeJSONCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"Prevent JSON serialization errors in Keras history.\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs:\n",
    "            for k, v in logs.items():\n",
    "                logs[k] = safe_float(v)\n",
    "\n",
    "class SafeReduceLROnPlateau(tf.keras.callbacks.ReduceLROnPlateau):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = {k: safe_float(v) for k, v in (logs or {}).items()}\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "\n",
    "# Weight-only checkpoint file (robust across TF versions)\n",
    "checkpoint_path = SAVE_DIR / \"best_image_model.weights.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    SafeJSONCallback(),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\", patience=5, mode=\"max\", restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(checkpoint_path),\n",
    "        monitor=\"val_auc\", save_best_only=True,\n",
    "        save_weights_only=True,   # ‚úÖ prevents broken .keras files\n",
    "        mode=\"max\", verbose=1),\n",
    "    SafeReduceLROnPlateau(\n",
    "        monitor=\"val_auc\", factor=0.3, patience=3, verbose=1, mode=\"max\"),\n",
    "]\n",
    "\n",
    "# Optional safety: clear old graphs before starting/continuing a long run\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Resume from checkpoint if available\n",
    "# -------------------------------------------------------------\n",
    "if checkpoint_path.exists():\n",
    "    print(f\"üîÅ Found existing checkpoint at {checkpoint_path}, resuming training (loading weights only)...\")\n",
    "    model.load_weights(checkpoint_path)\n",
    "else:\n",
    "    print(\"üöÄ Starting new training run from scratch...\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Determine last completed epoch\n",
    "# -------------------------------------------------------------\n",
    "history_path = SAVE_DIR / \"training_history_best.csv\"\n",
    "initial_epoch = 0\n",
    "if history_path.exists():\n",
    "    hist = pd.read_csv(history_path)\n",
    "    initial_epoch = len(hist)\n",
    "    print(f\"‚è© Resuming training from epoch {initial_epoch} of {EPOCHS}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Train\n",
    "# -------------------------------------------------------------\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    initial_epoch=initial_epoch,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "# -------------------------------------------------------------\n",
    "# Evaluate\n",
    "# -------------------------------------------------------------\n",
    "results = model.evaluate(test_ds, return_dict=True)\n",
    "print(\"\\n‚úÖ Final Test Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "pd.DataFrame(history.history).to_csv(SAVE_DIR / \"training_history_best.csv\", index=False)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Save model and embeddings\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nüíæ Saving model and feature embeddings...\")\n",
    "\n",
    "# Save in pure TensorFlow SavedModel format (robust & safe)\n",
    "tf.saved_model.save(model, str(SAVE_DIR / \"baseline_image_model_full_tf\"))\n",
    "print(\"‚úÖ Model saved successfully (TensorFlow SavedModel format).\")\n",
    "\n",
    "\n",
    "#  I WANT TO IGNORE THIS PART FOR NOW, because it works on the all dataset and have a large runtime.\n",
    "\n",
    "# # Extract feature embeddings\n",
    "# feature_extractor = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "# all_paths = merged[\"slice_path\"].tolist()\n",
    "# batch_size = 32\n",
    "# embeddings = []\n",
    "\n",
    "# for i in range(0, len(all_paths), batch_size):\n",
    "#     batch_imgs = [decode_img(p) for p in all_paths[i:i+batch_size]]\n",
    "#     batch_tensor = tf.stack(batch_imgs)\n",
    "#     emb = feature_extractor(batch_tensor).numpy()\n",
    "#     embeddings.append(emb)\n",
    "\n",
    "# embeddings = np.vstack(embeddings)\n",
    "# np.save(SAVE_DIR / \"image_embeddings_full.npy\", embeddings)\n",
    "# pd.DataFrame({\n",
    "#     \"slice_path\": all_paths,\n",
    "#     \"label\": merged[\"label\"].tolist()\n",
    "# }).to_csv(SAVE_DIR / \"image_embeddings_index_full.csv\", index=False)\n",
    "\n",
    "# print(f\"‚úÖ Embeddings saved: {embeddings.shape} ‚Üí {SAVE_DIR/'image_embeddings_full.npy'}\")\n",
    "# print(\"üéØ Training complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
